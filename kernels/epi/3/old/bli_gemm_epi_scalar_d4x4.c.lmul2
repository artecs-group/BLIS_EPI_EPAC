#include "blis.h"


void bli_sgemm_epi_scalar_4x4
     (
       dim_t               k0,
       float*     restrict alpha,
       float*     restrict a,
       float*     restrict b,
       float*     restrict beta,
       float*     restrict c, inc_t rs_c0, inc_t cs_c0,
       auxinfo_t* restrict data,
       cntx_t*    restrict cntx
     )
{
	printf(" uKernel SP\n" );	

	// Typecast local copies of integers in case dim_t and inc_t are a
	// different size than is expected by load instructions.
	uint32_t k_iter = k0 / 4;
	uint32_t k_left = k0 % 4;
	uint32_t rs_c   = rs_c0;
	uint32_t cs_c   = cs_c0;
	uint32_t i;

	void* a_next = bli_auxinfo_next_a( data );
	void* b_next = bli_auxinfo_next_b( data );

	long gvl = __builtin_epi_vsetvl( 4, __epi_e32, __epi_m2 );
	//float32x4_t alphav;
	__epi_4xf32 alphav;
	//alphav = vmovq_n_f32( *alpha );
	alphav = __builtin_epi_vfmv_v_f_4xf32( *alpha, gvl );

	//float32x4_t av1;
	__epi_4xf32 av1;
	//float32x4_t av2;
	__epi_4xf32 av2;
	//float32x4_t av3;
	__epi_4xf32 av3;
	//float32x4_t av4;
	__epi_4xf32 av4;

	//float32x4_t bv1;
	__epi_4xf32 bv1;
	//float32x4_t bv2;
	__epi_4xf32 bv2;
	//float32x4_t bv3;
	__epi_4xf32 bv3;
	//float32x4_t bv4;
	__epi_4xf32 bv4;

	// Vector for column 0
	//float32x4_t cv0;
	__epi_4xf32 cv0;
	// Vector for column 1
	//float32x4_t cv1;
	__epi_4xf32 cv1;
	// Vector for column 2
	//float32x4_t cv2;
	__epi_4xf32 cv2;
	// Vector for column 3
	//float32x4_t cv3;
	__epi_4xf32 cv3;

	if( rs_c == 1 )
	{
		// Load column 0
 		//cv0 = vld1q_f32( c + 0*rs_c + 0*cs_c ); 
 		cv0 = __builtin_epi_vload_4xf32( c + 0*rs_c + 0*cs_c, gvl ); 
	
		// Load column 1
 		//cv1 = vld1q_f32( c + 0*rs_c + 1*cs_c ); 
 		cv1 = __builtin_epi_vload_4xf32( c + 0*rs_c + 1*cs_c, gvl ); 
	
		// Load column 2
 		//cv2 = vld1q_f32( c + 0*rs_c + 2*cs_c ); 
 		cv2 = __builtin_epi_vload_4xf32( c + 0*rs_c + 2*cs_c, gvl ); 
	
		// Load column 3
 		//cv3 = vld1q_f32( c + 0*rs_c + 3*cs_c ); 
 		cv3 = __builtin_epi_vload_4xf32( c + 0*rs_c + 3*cs_c, gvl ); 
	}	

	// Vector for accummulating column 0
	//float32x4_t abv0;
	__epi_4xf32 abv0;
	// Initialize vector to 0.0
	//abv0 = vmovq_n_f32( 0.0 );
	abv0 = __builtin_epi_vfmv_v_f_4xf32( 0.0, gvl );

	// Vector for accummulating column 1
	//float32x4_t abv1;
	__epi_4xf32 abv1;
	// Initialize vector to 0.0
	//abv1 = vmovq_n_f32( 0.0 );
	abv1 = __builtin_epi_vfmv_v_f_4xf32( 0.0, gvl );

	// Vector for accummulating column 2
	//float32x4_t abv2;
	__epi_4xf32 abv2;
	// Initialize vector to 0.0
	//abv2 = vmovq_n_f32( 0.0 );
	abv2 = __builtin_epi_vfmv_v_f_4xf32( 0.0, gvl );

	// Vector for accummulating column 3
	//float32x4_t abv3;
	__epi_4xf32 abv3;
	// Initialize vector to 0.0
	//abv3 = vmovq_n_f32( 0.0 );
	abv3 = __builtin_epi_vfmv_v_f_4xf32( 0.0, gvl );
#if 0

	for ( i = 0; i < k_iter; ++i ) 
	{ 
		// Begin iter 0
 		//av1 = vld1q_f32( a ); 
 		av1 = __builtin_epi_vload_4xf32( a, gvl ); 

 		//bv1 = vld1q_f32( b ); 
 		bv1 = __builtin_epi_vload_4xf32( b, gvl ); 

		//abv0 = vmlaq_lane_f32( abv0, av1, vget_low_f32(bv1), 0 );
		abv0 = __builtin_epi_vsplat_4xf32( bv1, 0, gvl );
		abv0 = __builtin_epi_vfmacc_4xf32( abv0, av1, abv0, gvl );
		//abv1 = vmlaq_lane_f32( abv1, av1, vget_low_f32(bv1), 1 );
		abv1 = __builtin_epi_vsplat_4xf32( bv1, 1, gvl );
		abv1 = __builtin_epi_vfmacc_4xf32( abv1, av1, abv1, gvl );
		//abv2 = vmlaq_lane_f32( abv2, av1, vget_high_f32(bv1), 0 );
		abv2 = __builtin_epi_vsplat_4xf32( bv1, 2, gvl );
		abv2 = __builtin_epi_vfmacc_4xf32( abv2, av1, abv2, gvl );
		//abv3 = vmlaq_lane_f32( abv3, av1, vget_high_f32(bv1), 1 );
		abv3 = __builtin_epi_vsplat_4xf32( bv1, 3, gvl );
		abv3 = __builtin_epi_vfmacc_4xf32( abv3, av1, abv3, gvl );

		//av2 = vld1q_f32( a+4 ); 
 		av2 = __builtin_epi_vload_4xf32( a+4, gvl ); 

 		//bv2 = vld1q_f32( b+4 ); 
 		bv2 = __builtin_epi_vload_4xf32( b+4, gvl ); 

		//abv0 = vmlaq_lane_f32( abv0, av2, vget_low_f32(bv2), 0 );
		abv0 = __builtin_epi_vsplat_4xf32( bv2, 0, gvl );
		abv0 = __builtin_epi_vfmacc_4xf32( abv0, av2, abv0, gvl );
		//abv1 = vmlaq_lane_f32( abv1, av2, vget_low_f32(bv2), 1 );
		abv1 = __builtin_epi_vsplat_4xf32( bv2, 1, gvl );
		abv1 = __builtin_epi_vfmacc_4xf32( abv1, av2, abv1, gvl );
		//abv2 = vmlaq_lane_f32( abv2, av2, vget_high_f32(bv2), 0 );
		abv2 = __builtin_epi_vsplat_4xf32( bv2, 2, gvl );
		abv2 = __builtin_epi_vfmacc_4xf32( abv2, av2, abv2, gvl );
		//abv3 = vmlaq_lane_f32( abv3, av2, vget_high_f32(bv2), 1 );
		abv3 = __builtin_epi_vsplat_4xf32( bv2, 3, gvl );
		abv3 = __builtin_epi_vfmacc_4xf32( abv3, av2, abv3, gvl );

		//av3 = vld1q_f32( a+8 ); 
 		av3 = __builtin_epi_vload_4xf32( a+8, gvl ); 

 		//bv3 = vld1q_f32( b+8 ); 
 		bv3 = __builtin_epi_vload_4xf32( b+8, gvl ); 

		//abv0 = vmlaq_lane_f32( abv0, av3, vget_low_f32(bv3), 0 );
		abv0 = __builtin_epi_vsplat_4xf32( bv3, 0, gvl );
		abv0 = __builtin_epi_vfmacc_4xf32( abv0, av3, abv0, gvl );
		//abv1 = vmlaq_lane_f32( abv1, av3, vget_low_f32(bv3), 1 );
		abv1 = __builtin_epi_vsplat_4xf32( bv3, 1, gvl );
		abv1 = __builtin_epi_vfmacc_4xf32( abv1, av3, abv1, gvl );
		//abv2 = vmlaq_lane_f32( abv2, av3, vget_high_f32(bv3), 0 );
		abv2 = __builtin_epi_vsplat_4xf32( bv3, 2, gvl );
		abv2 = __builtin_epi_vfmacc_4xf32( abv2, av3, abv2, gvl );
		//abv3 = vmlaq_lane_f32( abv3, av3, vget_high_f32(bv3), 1 );
		abv3 = __builtin_epi_vsplat_4xf32( bv3, 3, gvl );
		abv3 = __builtin_epi_vfmacc_4xf32( abv3, av3, abv3, gvl );

		//av4 = vld1q_f32( a+12); 
 		av4 = __builtin_epi_vload_4xf32( a+12, gvl ); 

 		//bv4 = vld1q_f32( b+12); 
 		bv4 = __builtin_epi_vload_4xf32( b+12, gvl ); 

		//abv0 = vmlaq_lane_f32( abv0, av4, vget_low_f32(bv4), 0 );
		abv0 = __builtin_epi_vsplat_4xf32( bv4, 0, gvl );
		abv0 = __builtin_epi_vfmacc_4xf32( abv0, av4, abv0, gvl );
		//abv1 = vmlaq_lane_f32( abv1, av4, vget_low_f32(bv4), 1 );
		abv1 = __builtin_epi_vsplat_4xf32( bv4, 1, gvl );
		abv1 = __builtin_epi_vfmacc_4xf32( abv1, av4, abv1, gvl );
		//abv2 = vmlaq_lane_f32( abv2, av4, vget_high_f32(bv4), 0 );
		abv2 = __builtin_epi_vsplat_4xf32( bv4, 2, gvl );
		abv2 = __builtin_epi_vfmacc_4xf32( abv2, av4, abv2, gvl );
		//abv3 = vmlaq_lane_f32( abv3, av4, vget_high_f32(bv4), 1 );
		abv3 = __builtin_epi_vsplat_4xf32( bv4, 3, gvl );
		abv3 = __builtin_epi_vfmacc_4xf32( abv3, av4, abv3, gvl );

		a += 16; 
		b += 16; 
	} 

	for ( i = 0; i < k_left; ++i ) 
	{ 
 		//av1 = vld1q_f32( a ); 
 		av1 = __builtin_epi_vload_4xf32( a, gvl ); 
	
 		//bv1 = vld1q_f32( b ); 
 		bv1 = __builtin_epi_vload_4xf32( b, gvl ); 

		//abv0 = vmlaq_lane_f32( abv0, av1, vget_low_f32(bv1), 0 );
		abv0 = __builtin_epi_vsplat_4xf32( bv1, 3, gvl );
		abv0 = __builtin_epi_vfmacc_4xf32( abv0, av1, abv0, gvl );
		//abv1 = vmlaq_lane_f32( abv1, av1, vget_low_f32(bv1), 1 );
		abv1 = __builtin_epi_vsplat_4xf32( bv1, 3, gvl );
		abv1 = __builtin_epi_vfmacc_4xf32( abv1, av1, abv1, gvl );
		//abv2 = vmlaq_lane_f32( abv2, av1, vget_high_f32(bv1), 0 );
		abv2 = __builtin_epi_vsplat_4xf32( bv1, 3, gvl );
		abv2 = __builtin_epi_vfmacc_4xf32( abv2, av1, abv2, gvl );
		//abv3 = vmlaq_lane_f32( abv3, av1, vget_high_f32(bv1), 1 );
		abv3 = __builtin_epi_vsplat_4xf32( bv1, 3, gvl );
		abv3 = __builtin_epi_vfmacc_4xf32( abv3, av1, abv3, gvl );

		a += 4; 
		b += 4; 
	}
#endif

	__epi_4xf32 betav;
	betav = __builtin_epi_vfmv_v_f_4xf32( *beta, gvl );

	//cv0 = vmulq_n_f32( cv0, *beta );
	cv0 = __builtin_epi_vfmul_4xf32( cv0, betav, gvl );
	//cv1 = vmulq_n_f32( cv1, *beta );
	cv1 = __builtin_epi_vfmul_4xf32( cv1, betav, gvl );
	//cv2 = vmulq_n_f32( cv2, *beta );
	cv2 = __builtin_epi_vfmul_4xf32( cv2, betav, gvl );
	//cv3 = vmulq_n_f32( cv3, *beta );
	cv3 = __builtin_epi_vfmul_4xf32( cv3, betav, gvl );

	//cv0 = vmlaq_f32( cv0, abv0, alphav );
	//This segfaults if cv0 = .... ( cv0, ...
	cv0 = __builtin_epi_vfmacc_4xf32( cv0, alphav, abv0, gvl );
	//cv1 = vmlaq_f32( cv1, abv1, alphav );
	cv1 = __builtin_epi_vfmacc_4xf32( cv1, alphav, abv1, gvl );
	//cv2 = vmlaq_f32( cv2, abv2, alphav );
	cv2 = __builtin_epi_vfmacc_4xf32( cv2, alphav, abv2, gvl );
	//cv3 = vmlaq_f32( cv3, abv3, alphav );
	cv3 = __builtin_epi_vfmacc_4xf32( cv3, alphav, abv3, gvl );

	if( rs_c == 1 )
	{
		// Store column 0
  		//vst1q_f32( c + 0*rs_c + 0*cs_c, cv0 ); 
		__builtin_epi_vstore_4xf32( c + 0*rs_c + 0*cs_c, cv0, gvl );
		// Store column 1
  		//vst1q_f32( c + 0*rs_c + 1*cs_c, cv1 ); 
		__builtin_epi_vstore_4xf32( c + 0*rs_c + 1*cs_c, cv1, gvl );
		// Store column 2
  		//vst1q_f32( c + 0*rs_c + 2*cs_c, cv2 ); 
		__builtin_epi_vstore_4xf32( c + 0*rs_c + 2*cs_c, cv2, gvl );
		// Store column 3
  		//vst1q_f32( c + 0*rs_c + 3*cs_c, cv3 ); 
		__builtin_epi_vstore_4xf32( c + 0*rs_c + 3*cs_c, cv3, gvl );
	}

}

void bli_dgemm_epi_scalar_4x4
     (
       dim_t               k0,
       double*     restrict alpha,
       double*     restrict a,
       double*     restrict b,
       double*     restrict beta,
       double*     restrict c, inc_t rs_c0, inc_t cs_c0,
       auxinfo_t* restrict data,
       cntx_t*    restrict cntx
     )
{
	printf(" uKernel DP\n" );	
}
